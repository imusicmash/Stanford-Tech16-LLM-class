{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imusicmash/Stanford-Tech16-LLM-class/blob/main/StanfordLLMClassWeek2_prompt_eng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code from Stanford LLM with Python class from Feb 15, 2024\n",
        "#StanfordTech16"
      ],
      "metadata": {
        "id": "Plu180a9k-TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "UAsj88npPdRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "open_ai_key = userdata.get('openai')\n",
        "client = OpenAI(api_key=open_ai_key)"
      ],
      "metadata": {
        "id": "Ft0dVY1iOLhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt engineering - few shot"
      ],
      "metadata": {
        "id": "0X61OO5zwVZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# few shot learning example.\n",
        "# large role: system\n",
        "def chat(message):\n",
        "    \"\"\"\n",
        "    Send a message to the OpenAI GPT-3.5 model and return its response.\n",
        "\n",
        "    This function interacts with the OpenAI API, specifically using the GPT-3.5-turbo model. It takes a user's message as input, sends it to the model, and returns the model's text-only response. The function ensures the AI's output is concise by providing a system-level instruction.\n",
        "\n",
        "    Parameters:\n",
        "    message (str): A string containing the user's message to the AI.\n",
        "\n",
        "    Returns:\n",
        "    str: The text response generated by the GPT-3.5 model.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        temperature=0.3,\n",
        "        # response_format={ \"type\": \"json_object\" },\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"\"\"\n",
        "              Below are examples of text messages and their classifications.\n",
        "              After studying these examples, please classify the new text message at the end.\n",
        "\n",
        "              Example 1:\n",
        "\n",
        "              Text: \"Can you send me the files by tomorrow? It's not urgent, but I'd like to review them.\"\n",
        "              Classification: Non-Urgent\n",
        "\n",
        "              Example 2:\n",
        "\n",
        "              Text: \"Please review the final report ASAP! We need it ready by our meeting in the morning!\"\n",
        "              Classification: Urgent\n",
        "\n",
        "              Example 3:\n",
        "\n",
        "              Text: \"Let's schedule a meeting for next week to discuss the project. No rush.\"\n",
        "              Classification: Non-Urgent\n",
        "              Example 4:\n",
        "\n",
        "              Text: \"URGENT: The server is down and needs immediate attention!\"\n",
        "              Classification: Urgent\n",
        "              \"\"\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Classify the following message: {message}\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    text_only = response.choices[0].message.content\n",
        "    return text_only\n"
      ],
      "metadata": {
        "id": "qYJ9ZnsKVsO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat(\"Reminder: Tomorrow's team meeting has been postponed. Please update your calendars\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qPxpNEraVsRP",
        "outputId": "1596434f-f73e-4e83-86d7-e00c6c950d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Classification: Non-Urgent'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat(\"Reminder: Tomorrow's team meeting has been postponed. Please update your calendars ASAP\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rTCmcQt0kSWw",
        "outputId": "397cb994-8c18-4fb9-9ea9-d6cf8b07fc23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Classification: Urgent'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat(\"Reminder: Next month's team meeting has been postponed. Please update your calendars ASAP\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NHlJWvLokWmo",
        "outputId": "eb640512-c421-46cb-c5c5-064567d4b9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Classification: Urgent'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat(\"Reminder: The paper is no longer due tomorrow at 3pm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SE05hhbJkgE8",
        "outputId": "ff6ab193-3bad-45e7-cf17-37e30e780038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Non-Urgent'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON mode and Log Probabilities"
      ],
      "metadata": {
        "id": "pHnNNONhZoTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just add logprobs = True\n",
        "# must use gpt-4 turbo.. only this one has log probbilities feature\n",
        "# -preview ensure you always use the latest one.. this one has the probabilities working\n",
        "\n",
        "def chat(message):\n",
        "    \"\"\"\n",
        "    Send a message to the OpenAI GPT-3.5 model and return its response.\n",
        "\n",
        "    This function interacts with the OpenAI API, specifically using the GPT-3.5-turbo model. It takes a user's message as input, sends it to the model, and returns the model's text-only response. The function ensures the AI's output is concise by providing a system-level instruction.\n",
        "\n",
        "    Parameters:\n",
        "    message (str): A string containing the user's message to the AI.\n",
        "\n",
        "    Returns:\n",
        "    str: The text response generated by the GPT-3.5 model.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4-turbo-preview\",\n",
        "        response_format={ \"type\": \"json_object\" },\n",
        "        logprobs=True,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"\"\"\n",
        "            You are a helpful assistant classifations.\n",
        "\n",
        "            Below are examples of text messages and their classifications. After studying these examples, please classify the new text message at the end.\n",
        "\n",
        "              Example 1:\n",
        "\n",
        "              Text: \"Can you send me the files by tomorrow? It's not urgent, but I'd like to review them.\"\n",
        "              Classification: Non-Urgent\n",
        "\n",
        "              Example 2:\n",
        "\n",
        "              Text: \"Please review the final report ASAP! We need it ready by our meeting in the morning!\"\n",
        "              Classification: Urgent\n",
        "\n",
        "              Example 3:\n",
        "\n",
        "              Text: \"Let's schedule a meeting for next week to discuss the project. No rush.\"\n",
        "              Classification: Non-Urgent\n",
        "\n",
        "              Example 4:\n",
        "\n",
        "              Text: \"URGENT: The server is down and needs immediate attention!\"\n",
        "              Classification: Urgent\n",
        "\n",
        "              \"\"\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Classify the following message as Non-Urgent or Urgent and return with probability as JSON: {message}\"}\n",
        "        ]\n",
        "    )\n",
        "    text_only = response.choices[0].message.content\n",
        "    return text_only\n"
      ],
      "metadata": {
        "id": "uV1xvaalaOxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat(\"Reminder: Tomorrow's team meeting has been postponed. Please update your calendars ASAP\")"
      ],
      "metadata": {
        "id": "TKx6kntUZtT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jlgy42XIdEjb",
        "outputId": "e2f25bb9-ab1b-4904-e6d0-c2086580cb52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Classification\": \"Non-Urgent\",\n",
            "  \"Probability\": 0.85\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat(\"Call me when you get a chance. I have something to tell you.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHlW1NcnlyAK",
        "outputId": "d1423f27-5bce-49f0-8e0e-b2c6549a5243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Classification\": \"Non-Urgent\",\n",
            "  \"Probability\": 0.85\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# just add logprobs = True\n",
        "# must use gpt-4 turbo.. only this one has log probbilities feature\n",
        "# -preview ensure you always use the latest one\n",
        "\n",
        "def classify_reason(message):\n",
        "    \"\"\"\n",
        "    Send a message to the OpenAI GPT-3.5 model and return its response.\n",
        "\n",
        "    This function interacts with the OpenAI API, specifically using the GPT-3.5-turbo model. It takes a user's message as input, sends it to the model, and returns the model's text-only response. The function ensures the AI's output is concise by providing a system-level instruction.\n",
        "\n",
        "    Parameters:\n",
        "    message (str): A string containing the user's message to the AI.\n",
        "\n",
        "    Returns:\n",
        "    str: The text response generated by the GPT-3.5 model.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4-turbo-preview\",\n",
        "        response_format={ \"type\": \"json_object\" },\n",
        "        logprobs=True,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"\"\"\n",
        "            You are a helpful assistant classifations.\n",
        "\n",
        "            Below are examples of text messages and their classifications. After studying these examples, please classify the new text message at the end.\n",
        "\n",
        "              Example 1:\n",
        "\n",
        "              Text: \"Can you send me the files by tomorrow? It's not urgent, but I'd like to review them.\"\n",
        "              Classification: Non-Urgent\n",
        "\n",
        "              Example 2:\n",
        "\n",
        "              Text: \"Please review the final report ASAP! We need it ready by our meeting in the morning!\"\n",
        "              Classification: Urgent\n",
        "\n",
        "              Example 3:\n",
        "\n",
        "              Text: \"Let's schedule a meeting for next week to discuss the project. No rush.\"\n",
        "              Classification: Non-Urgent\n",
        "\n",
        "              Example 4:\n",
        "\n",
        "              Text: \"URGENT: The server is down and needs immediate attention!\"\n",
        "              Classification: Urgent\n",
        "\n",
        "              \"\"\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Classify the following message as Non-Urgent or Urgent and return with probability as JSON. Also return the reasoning for why you think this is the classification: {message}\"}\n",
        "        ]\n",
        "    )\n",
        "    text_only = response.choices[0].message.content\n",
        "    return text_only\n"
      ],
      "metadata": {
        "id": "fidmPkdBnBM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classify_reason(\"Call me when you get a chance. I have something to tell you.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRJ6qUsKnSns",
        "outputId": "5a4292f2-ef20-4720-981b-2af11e6ff47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"classification\": \"Non-Urgent\",\n",
            "  \"probability\": 0.85,\n",
            "  \"reasoning\": \"The text 'Call me when you get a chance. I have something to tell you.' suggests that the message can be addressed at the recipient's convenience, indicating no immediate pressure or time-sensitive urgency. The phrase 'when you get a chance' specifically connotes a flexible timing, aligning more with a non-urgent classification. However, the mention of having something to tell adds a slight element of uncertainty regarding the urgency, which is why the probability is not higher.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# just add logprobs = True\n",
        "# must use gpt-4 turbo.. only this one has log probbilities feature\n",
        "# -preview ensure you always use the latest one\n",
        "\n",
        "def classify_reason_apple(message):\n",
        "    \"\"\"\n",
        "    Send a message to the OpenAI GPT-3.5 model and return its response.\n",
        "\n",
        "    This function interacts with the OpenAI API, specifically using the GPT-3.5-turbo model. It takes a user's message as input, sends it to the model, and returns the model's text-only response. The function ensures the AI's output is concise by providing a system-level instruction.\n",
        "\n",
        "    Parameters:\n",
        "    message (str): A string containing the user's message to the AI.\n",
        "\n",
        "    Returns:\n",
        "    str: The text response generated by the GPT-3.5 model.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4-turbo-preview\",\n",
        "        response_format={ \"type\": \"json_object\" },\n",
        "        logprobs=True,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"\"\"\n",
        "            You are a helpful assistant that loves Apples.\n",
        "\n",
        "            Below are examples of text messages and their classifications. After studying these examples, please classify the new text message at the end.\n",
        "\n",
        "              Example 1:\n",
        "\n",
        "              Text: \"Can you send me the files by tomorrow? It's not urgent, but I'd like to review them.\"\n",
        "              Apples: Non-Urgent\n",
        "\n",
        "              Example 2:\n",
        "\n",
        "              Text: \"Please review the final report ASAP! We need it ready by our meeting in the morning!\"\n",
        "              Apples: Urgent\n",
        "\n",
        "              Example 3:\n",
        "\n",
        "              Text: \"Let's schedule a meeting for next week to discuss the project. No rush.\"\n",
        "              Apples: Non-Urgent\n",
        "\n",
        "              Example 4:\n",
        "\n",
        "              Text: \"URGENT: The server is down and needs immediate attention!\"\n",
        "              Apples: Urgent\n",
        "\n",
        "              \"\"\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Apple the following message as Non-Urgent or Urgent and return with probability as JSON. : {message}\"}\n",
        "        ]\n",
        "    )\n",
        "    text_only = response.choices[0].message.content\n",
        "    return text_only\n"
      ],
      "metadata": {
        "id": "IvoHLIninfhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classify_reason_apple(\"Call me when you get a chance. I have something to tell you.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atxb14gHnzNw",
        "outputId": "42dd792b-5139-441d-b4c7-daae07224682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Apples\": \"Non-Urgent\",\n",
            "  \"Probability\": 0.85\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classify_reason_apple(\"Call me now. I have something to tell you.\"))"
      ],
      "metadata": {
        "id": "oKOF7XNOv_Z1",
        "outputId": "1ad8a27f-0dcf-496e-ebb7-e3e00a927e09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Apples\": \"Urgent\",\n",
            "  \"Probability\": 0.75\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try not to go over 20 categories"
      ],
      "metadata": {
        "id": "5Wpaw47SmbDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain of thought reasoning"
      ],
      "metadata": {
        "id": "Kmzn4ktYRty4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message):\n",
        "    \"\"\"\n",
        "    Send a message to the OpenAI GPT model and return its response.\n",
        "\n",
        "    This function interacts with the OpenAI API, specifically using the GPT model. It takes a user's message as input, sends it to the model, and returns the model's text-only response. The function ensures the AI's output is concise by providing a system-level instruction.\n",
        "\n",
        "    Parameters:\n",
        "    message (str): A string containing the user's message to the AI.\n",
        "\n",
        "    Returns:\n",
        "    str: The text response generated by the GPT model.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4-turbo-preview\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"\"\"\n",
        "            You are a helpful assistant classifations.\n",
        "\n",
        "            Below are examples of questions and how to calculate the answer\n",
        "\n",
        "              Example 1: Arithmetic Problem\n",
        "              Prompt: \"If a shirt costs $20 and there is a 10% discount, how much does the shirt cost after the discount?\"\n",
        "              Chain of Thought Answer:\n",
        "                Calculate the amount of discount: 10% of $20 is $2.\n",
        "                Subtract the discount from the original price: $20 - $2 = $18.\n",
        "                The shirt costs $18 after the discount.\n",
        "\n",
        "              Example 2: Logic Puzzle\n",
        "              Prompt: \"There are four apples and you take away three. How many apples do you have?\"\n",
        "              Chain of Thought Answer:\n",
        "                You start with four apples.\n",
        "                You take away three apples.\n",
        "                After taking three, you now have those three apples.\n",
        "                You have 3 apples\n",
        "\n",
        "              \"\"\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Answer the following question: {message}\"}\n",
        "        ]\n",
        "    )\n",
        "    text_only = response.choices[0].message.content\n",
        "    return text_only\n"
      ],
      "metadata": {
        "id": "bJR8Sy2vRzcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat(\"If a tree absorbs 48 pounds of CO2 a year, how much CO2 will 10 trees absorb in a year?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC9PUbrjSZbZ",
        "outputId": "21a4200f-d0cd-4555-a8ed-59474d657d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To find out how much CO2 10 trees will absorb in a year, follow these steps:\n",
            "\n",
            "1. Determine how much CO2 one tree absorbs in a year: 48 pounds.\n",
            "2. Multiply the amount absorbed by one tree by the number of trees: 48 pounds/tree Ã— 10 trees = 480 pounds.\n",
            "\n",
            "So, 10 trees will absorb 480 pounds of CO2 in a year.\n"
          ]
        }
      ]
    }
  ]
}